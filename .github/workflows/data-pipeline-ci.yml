name: Data Pipeline CI

on:
  push:
    branches: [main]
    paths:
      - 'data-pipeline/**'
      - 'docker/**'
      - '.github/workflows/**'
  pull_request:
    branches: [dev, main, release/*]
    paths:
      - 'data-pipeline/**'
      - 'docker/**'
      - '.github/workflows/**'

env:
  PYTHON_VERSION: "3.11"
  POETRY_VERSION: "1.7.0"

# Cancel in-progress runs for the same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # ===========================================================================
  # JOB 1: LINT AND FORMAT
  # Fast feedback - runs in ~30-45 seconds
  # ===========================================================================
  lint:
    name: Lint & Format Check
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-lint-${{ hashFiles('data-pipeline/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-lint-

      - name: Install linting tools
        run: |
          python -m pip install --upgrade pip
          pip install ruff==0.1.9 black==23.12.1 mypy==1.8.0

      - name: Run Ruff (linting)
        run: |
          ruff check data-pipeline/ --output-format=github
        continue-on-error: false

      - name: Run Black (formatting check)
        run: |
          black --check --diff data-pipeline/

  # ===========================================================================
  # JOB 2: UNIT TESTS
  # Core test suite with coverage enforcement
  # ===========================================================================
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: lint
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-test-${{ hashFiles('data-pipeline/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-test-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          cd data-pipeline
          pip install -e ".[dev]"

      - name: Run unit tests with coverage
        run: |
          cd data-pipeline
          pytest tests/unit/ \
            -v \
            --cov=src \
            --cov-report=xml \
            --cov-report=term-missing \
            --cov-fail-under=70 \
            --tb=short \
            -x  # Stop on first failure for faster feedback
        env:
          PYTHONPATH: ${{ github.workspace }}/data-pipeline

      - name: Upload coverage report
        uses: codecov/codecov-action@v3
        if: always()
        with:
          file: data-pipeline/coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false

  # ===========================================================================
  # JOB 3: SCHEMA TESTS
  # Validate all schema definitions and enforcement logic
  # ===========================================================================
  schema-tests:
    name: Schema Validation Tests
    runs-on: ubuntu-latest
    needs: lint
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-schema-${{ hashFiles('data-pipeline/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-schema-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          cd data-pipeline
          pip install -e ".[dev]"

      - name: Validate schema JSON files
        run: |
          cd data-pipeline
          python -c "
          import json
          import sys
          from pathlib import Path

          schemas_dir = Path('schemas')
          if not schemas_dir.exists():
              print('No schemas directory found, skipping validation')
              sys.exit(0)

          errors = []
          for schema_file in schemas_dir.rglob('*.json'):
              try:
                  with open(schema_file) as f:
                      json.load(f)
                  print(f'✓ {schema_file}')
              except json.JSONDecodeError as e:
                  errors.append(f'✗ {schema_file}: {e}')

          if errors:
              for error in errors:
                  print(error)
              sys.exit(1)

          print(f'All schema files are valid JSON')
          "

      - name: Run schema tests
        run: |
          cd data-pipeline
          pytest tests/schema_tests/ -v --tb=short || echo "No schema tests found yet"
        env:
          PYTHONPATH: ${{ github.workspace }}/data-pipeline

  # ===========================================================================
  # JOB 4: DAG VALIDATION
  # Ensure all Airflow DAGs are syntactically correct and importable
  # ===========================================================================



  # ===========================================================================
  # JOB 5: INTEGRATION TESTS
  # Full pipeline tests - only on main/dev branches
  # ===========================================================================
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [unit-tests, schema-tests]
    timeout-minutes: 30
    if: github.base_ref == 'main' || github.base_ref == 'dev'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-integration-${{ hashFiles('data-pipeline/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-integration-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          cd data-pipeline
          pip install -e ".[dev]"

      - name: Run integration tests
        run: |
          cd data-pipeline
          pytest tests/integration/ \
            -v \
            --timeout=300 \
            --tb=short \
            || echo "No integration tests found yet"
        env:
          PYTHONPATH: ${{ github.workspace }}/data-pipeline
          STORAGE_EMULATOR_HOST: http://localhost:4443
          BP_ENVIRONMENT: dev
